{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fac9d630",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Teoroo-CMC/DoE_Course_Material/blob/main/Week_2/workshop_4/Jupyter-notebooks/2-6factor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12a3edb8",
   "metadata": {},
   "source": [
    "# A Two-Level, Six-Factor Full Factorial Design\n",
    "\n",
    "## Introduction\n",
    "This notebook roughly follows content from Box and Draper's Empirical Model-Building and Response Surfaces (Wiley, 1984). This content is covered by Chapter 4 of Box and Draper.\n",
    "\n",
    "In this notebook, we'll carry out an anaylsis of a full factorial design, and show how we can obtain information about a system and its responses, and a quantifiable range of certainty about those values. This is the fundamental idea behind empirical model-building and allows us to construct cheap and simple models to represent complex, nonlinear systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5829c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import rand, seed\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "seed(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "876ac13c",
   "metadata": {},
   "source": [
    "## Two-Level Six-Factor Full Factorial Design\n",
    "Let's start with our six-factor factorial design example. Six factors means there are six input variables; this is still a two-level experiment, so this is now a  2$^6$-factorial experiment.\n",
    "\n",
    "Additionally, there are now three response variables,  (y$_1$,y$_2$,y$_3$)\n",
    " .\n",
    "\n",
    "To generate a table of the 64 experiments to be run at each factor level, we will use the itertools.product function below. This is all put into a DataFrame.\n",
    "\n",
    "This example generates some random response data, by multiplying a vector of random numbers by the vector of input variable values. (Nothing too complicated.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418791ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Create the inputs:\n",
    "encoded_inputs = list( itertools.product([-1,1],[-1,1],[-1,1],[-1,1],[-1,1],[-1,1]) )\n",
    "\n",
    "# Create the experiment design table:\n",
    "doe = pd.DataFrame(encoded_inputs,columns=['x%d'%(i+1) for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bff432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Manufacture\" observed data y\n",
    "doe['y1'] = doe.apply( lambda z : sum([ rand()*z[\"x%d\"%(i)]+0.01*(0.5-rand()) for i in range(1,7) ]), axis=1)\n",
    "doe['y2'] = doe.apply( lambda z : sum([ 5*rand()*z[\"x%d\"%(i)]+0.01*(0.5-rand()) for i in range(1,7) ]), axis=1)\n",
    "doe['y3'] = doe.apply( lambda z : sum([ 100*rand()*z[\"x%d\"%(i)]+0.01*(0.5-rand()) for i in range(1,7) ]), axis=1)\n",
    "print(doe[['y1','y2','y3']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5bf3143",
   "metadata": {},
   "source": [
    "## Defining Variables and Variable Labels\n",
    "Next we'll define some containers for input variable labels, output variable labels, and any interaction terms that we'll be computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350898a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "labels[1] = ['x1','x2','x3','x4','x5','x6']\n",
    "for i in [2,3,4,5,6]:\n",
    "    labels[i] = list(itertools.combinations(labels[1], i))\n",
    "\n",
    "obs_list = ['y1','y2','y3']\n",
    "\n",
    "for k in labels.keys():\n",
    "    print(str(k) + \" : \" + str(labels[k]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4abb556e",
   "metadata": {},
   "source": [
    "Now that we have variable labels for each main effect and interaction effect, we can actually compute those effects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "628b3b50",
   "metadata": {},
   "source": [
    "## Computing Main and Interaction Effects\n",
    "We'll start by finding the constant effect, which is the mean of each response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1113763",
   "metadata": {},
   "outputs": [],
   "source": [
    "effects = {}\n",
    "\n",
    "# Start with the constant effect: this is $\\overline{y}$\n",
    "effects[0] = {'x0' : [doe['y1'].mean(),doe['y2'].mean(),doe['y3'].mean()]}\n",
    "print(effects[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47a35373",
   "metadata": {},
   "source": [
    "Next, compute the main effect of each variable, which quantifies the amount the response changes by when the input variable is changed from the -1 to +1 level. That is, it computes the average effect of an input variable  x$_i$\n",
    "  on each of the three response variables  y$_1$,y$_2$,y$_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aec4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "effects[1] = {}\n",
    "for key in labels[1]:\n",
    "    effects_result = []\n",
    "    for obs in obs_list:\n",
    "        effects_df = doe.groupby([key])[obs].mean()\n",
    "        result = sum([ zz*effects_df.loc[zz] for zz in effects_df.index ])\n",
    "        effects_result.append(result)\n",
    "    effects[1][key] = effects_result\n",
    "\n",
    "effects[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82363a9d",
   "metadata": {},
   "source": [
    "Our next step is to crank through each variable interaction level: two-variable, three-variable, and on up to six-variable interaction effects. We compute interaction effects for each two-variable combination, three-variable combination, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9220cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [2,3,4,5,6]:\n",
    "    effects[c] = {}\n",
    "    for key in labels[c]:\n",
    "        effects_result = []\n",
    "        for obs in obs_list:\n",
    "            effects_df = doe.groupby([key[0],key[1]])[obs].mean()\n",
    "            result = sum([ np.prod(zz)*effects_df.loc[zz]/(2**(len(zz)-1)) for zz in effects_df.index ])\n",
    "            effects_result.append(result)\n",
    "        effects[c][key] = effects_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb030c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printd(d):\n",
    "    for k in d.keys():\n",
    "        print(\"%25s : %s\"%(k,d[k]))\n",
    "\n",
    "for i in range(1,7):\n",
    "    printd(effects[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f83d24e1",
   "metadata": {},
   "source": [
    "We've computed the main and interaction effects for every variable combination (whew!), but now we're at a point where we want to start doing things with these quantities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53f505f8",
   "metadata": {},
   "source": [
    "# Analyzing Effects\n",
    "The first and most important question is, what variable, or combination of variables, has the strongest effect on the three responses  y$_1$?  y$_2$? y$_3$?\n",
    "\n",
    "To figure this out, we'll need to use the data we computed above. Python makes it easy to slice and dice data. In this case, we've constructed a nested dictionary, with the outer keys mapping to the number of variables and inner keys mapping to particular combinations of input variables. Its pretty easy to convert this to a flat data structure that we can use to sort by variable effects. We've got six \"levels\" of variable combinations, so we'll flatten effects by looping through all six dictionaries of variable combinations (from main effects to six-variable interaction effects), and adding each entry to a master dictionary.\n",
    "\n",
    "The master dictionary will be a flat dictionary, and once we've populated it, we can use it to make a DataFrame for easier sorting, printing, manipulating, aggregating, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(effects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8740c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {}\n",
    "for nvars in effects.keys():\n",
    "\n",
    "    effect = effects[nvars]\n",
    "    for k in effect.keys():\n",
    "        v = effect[k]\n",
    "        master_dict[k] = v\n",
    "\n",
    "master_df = pd.DataFrame(master_dict).T\n",
    "master_df.columns = obs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd53214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = master_df['y1'].copy()\n",
    "y1.sort_values(inplace=True,ascending=False)\n",
    "\n",
    "print(\"Top 10 effects for observable y1:\")\n",
    "print(y1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = master_df['y2'].copy()\n",
    "y2.sort_values(inplace=True,ascending=False)\n",
    "\n",
    "print(\"Top 10 effects for observable y2:\")\n",
    "print(y2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee01ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = master_df['y3'].copy()\n",
    "y3.sort_values(inplace=True,ascending=False)\n",
    "\n",
    "print(\"Top 10 effects for observable y3:\")\n",
    "print(y3[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc998800",
   "metadata": {},
   "source": [
    "If we were only to look at the list of rankings of each variable, we would see that each response is affected by different input variables, listed below in order of descending importance:\n",
    "\n",
    "y1: 136254\n",
    "y2: 561234\n",
    "y3: 453216\n",
    "\n",
    "This is a somewhat mixed message that's hard to interpret - can we get rid of variable 2? We can't eliminate 1, 4, or 5, and probably not 3 or 6 either.\n",
    "\n",
    "First, let's look at Pareto charts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10ae77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "master_df\n",
    "indexes=['y1', 'y2', 'y3']\n",
    "for ii in indexes: \n",
    "    effects_df=pd.DataFrame(master_df[ii].abs())\n",
    "    effects_df = effects_df.sort_values(by=ii, ascending=False)\n",
    "# Add cumulative percentage column\n",
    "    effects_df[\"cum_percentage\"] = round(effects_df[ii].cumsum()/effects_df[ii].sum()*100,2)\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "# Set figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(22,10))\n",
    "\n",
    "# Plot bars (i.e. frequencies)\n",
    "    ax.set_title(\"Pareto Chart\")\n",
    "    ax.set_xlabel(\"Parameter\")\n",
    "    ax.set_ylabel(\"Frequency\");\n",
    "    effects_df[ii].plot.bar(y='Standardized effect', ax=ax)\n",
    "#    ax.axhline(2.06, color=\"orange\", linestyle=\"dashed\")\n",
    "\n",
    "# Second y axis (i.e. cumulative percentage)\n",
    "    ax2 = ax.twinx()\n",
    "#ax2.plot(effects_df.index, effects_df[\"cum_percentage\"], color=\"red\", marker=\"D\", ms=7)\n",
    "    effects_df.plot(y=\"cum_percentage\", color=\"red\", marker=\"D\", ms=7, ax=ax2)\n",
    "    ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "    ax2.set_ylabel(\"Cumulative Percentage\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30d55902",
   "metadata": {},
   "source": [
    "However, looking at the quantile-quantile plot of the effects answers the question in a more visual way.\n",
    "\n",
    "## Quantile-Quantile Effects Plot\n",
    "We can examine the distribution of the various input variable effects using a quantile-quantile plot of the effects. Quantile-quantile plots arrange the effects in order from least to greatest, and can be applied in several contexts (as we'll see below, when assessing model fits). If the quantities plotted on a quantile-qantile plot are normally distributed, they will fall on a straight line; data that do not fall on the straight line indicate significant deviations from normal behavior.\n",
    "\n",
    "In the case of a quantile-quantile plot of effects, non-normal behavior means the effect is paticularly strong. By identifying the outlier points on thse quantile-quantile plots (they're ranked in order, so they correspond to the lists printed above), we can identify the input variables most likely to have a strong impact on the responses.\n",
    "\n",
    "We need to look both at the top (the variables that have the largest overall positive effect) and the bottom (the variables that have the largest overall negative effect) for significant outliers. When we find outliers, we can add them to a list of variabls that we have decided are important and will keep in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ff7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify which effects are not normally distributed, \n",
    "# to assist in identifying important variables\n",
    "\n",
    "fig = figure(figsize=(14,4))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "stats.probplot(y1, dist=\"norm\", plot=ax1)\n",
    "ax1.set_title('y1')\n",
    "\n",
    "stats.probplot(y2, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('y2')\n",
    "\n",
    "stats.probplot(y3, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('y3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14de8cf",
   "metadata": {},
   "source": [
    "Normally, we would use the main effects that were computed, and their rankings, to eliminate any variables that don't have a strong effect on any of our variables. However, this analysis shows that sometimes we can't eliminate any variables.\n",
    "\n",
    "All six input variables are depicted as the effects that fall far from the red line - indicating all have a statistically meaningful (i.e., not normally distributed) effect on all three response variables. This means we should keep all six factors in our analysis.\n",
    "\n",
    "There is also a point on the  y3\n",
    "  graph that appears significant on the bottom. Examining the output of the lists above, this point represents the effect for the six-way interaction of all input variables. High-order interactions are highly unlikely (and in this case it is a numerical artifact of the way the responses were generated), so we'll keep things simple and stick to a linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
