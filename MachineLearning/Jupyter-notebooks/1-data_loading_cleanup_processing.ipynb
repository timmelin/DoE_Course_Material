{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading, cleanup and processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to a ML project is to obtain the dataset you will be working with. \n",
    "There are many repositories for materials science-specific data (whether online or offline)---consult the accompanying paper for a list of the more commonly used ones.\n",
    "\n",
    "Once you have identified the repository and dataset you will use for your project, you will have to download it to your local machine, or establish a way to reliably access the dataset.\n",
    "Consult the documentation of the repository for how to do this.\n",
    "\n",
    "For this tutorial, we have collected heat capacity ($C_p$) data from the [NIST-JANAF Thermochemical Tables](https://doi.org/10.18434/T42S31)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Using Pandas, we read in the dataset into a DataFrame. \n",
    "\n",
    "We also print the shape of the DataFrame, which indicates the number of rows and columns in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "data_path = os.path.join(PATH, 'data/cp_data_demo.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f'Original DataFrame shape: {df.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our input dataset has 4583 data samples, each with 3 variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the data\n",
    "\n",
    "We examine some rows and look at the data's basic statistics.\n",
    "\n",
    "We see that the dataset contains information about the formula, measurement condition (in this case, temperature in K), and the target property, heat capacity (in J/(mol * K))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing you should notice: we have many observations of the same compound (B2O3) but measured at different measurement conditions, resulting in a different property value.\n",
    "\n",
    "We can get some simple summary statistics of the DataFrame by calling the `.describe()` method on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `pandas-profiling` library, we can generate a more in-depth report of our starting dataset.\n",
    "Note that generating this profile report might take upwards of 20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df.copy(), title='Pandas Profiling Report of Cp dataset', html={'style':{'full_width':True}})\n",
    "profile.to_widgets()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a few things from the profile report:\n",
    "* We have some missing cells in the dataset (\"Overview\" tab)\n",
    "* We have some unrealistic Temperature and Heat Capacity values in the dataset (\"Variables\" tab)\n",
    "* We have some missing Temperature, Formula and Heat Capacity values in the dataset (\"Variables\" tab)\n",
    "\n",
    "Also notice that on the \"Overview\" tab, there is the following warning: `FORMULA` has a high cardinality: 245 distinct values.\n",
    "\n",
    "Cardinality is the number of distinct values in a column of a table, relative to the number of rows in the table.\n",
    "In our dataset, we have a total of 4583 data observations, but only 245 distinct formulae.\n",
    "We will have to keep this in mind later, when we process and split the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the column names for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'FORMULA': 'formula',\n",
    "               'CONDITION: Temperature (K)': 'T',\n",
    "               'PROPERTY: Heat Capacity (J/mol K)': 'Cp'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for and remove `NaN` values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can use the built-in Pandas methods to check for `NaN` values in the dataset, which are missing values.\n",
    "We then remove the dataset rows which contain `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the respective dataset columns, and get the indices\n",
    "df2 = df.copy()\n",
    "bool_nans_formula = df2['formula'].isnull()\n",
    "bool_nans_T = df2['T'].isnull()\n",
    "bool_nans_Cp = df2['Cp'].isnull()\n",
    "\n",
    "# Drop the rows of the DataFrame which contain NaNs\n",
    "df2 = df2.drop(df2.loc[bool_nans_formula].index, axis=0)\n",
    "df2 = df2.drop(df2.loc[bool_nans_T].index, axis=0)\n",
    "df2 = df2.drop(df2.loc[bool_nans_Cp].index, axis=0)\n",
    "\n",
    "print(f'DataFrame shape before dropping NaNs: {df.shape}')\n",
    "print(f'DataFrame shape after dropping NaNs: {df2.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also includes the convenient built-in method `.dropna()` to check for and remove `NaNs` in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df3 = df3.dropna(axis=0, how='any')\n",
    "\n",
    "print(f'DataFrame shape before dropping NaNs: {df.shape}')\n",
    "print(f'DataFrame shape after dropping NaNs: {df3.shape}')\n",
    "\n",
    "df = df3.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for and remove unrealistic values\n",
    "\n",
    "In some cases, you might also get data values that simply don't make sense.\n",
    "For our dase, this could be negative values in the temperature or heat capacity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_invalid_T = df['T'] < 0\n",
    "bool_invalid_Cp = df['Cp'] < 0\n",
    "\n",
    "df = df.drop(df.loc[bool_invalid_T].index, axis=0)\n",
    "df = df.drop(df.loc[bool_invalid_Cp].index, axis=0)\n",
    "\n",
    "print(f'Cleaned DataFrame shape: {df.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data to csv\n",
    "\n",
    "Finally, after cleaning and processing the data, you can save it to disk in a cleaned state for you to use later.\n",
    "\n",
    "Pandas allows us to save our data as a comma separated value `.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(PATH, 'data/cp_data_cleaned.csv')\n",
    "df.to_csv(out_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, your data can be saved in other file formats (such as hdf5) or in databases (such as SQL), but we will not go into the details of these formats.\n",
    "\n",
    "Typically, the amount of data you can gather for your ML project isn't large enough to warrant these approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_book_II",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3af2cce238079744ade4380fab4e623f56bf17adac44d2cac1f930dd9ee5f19a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
